{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter, ImageOps, ImageDraw\n",
    "import PIL\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOLOv*** MUST have label data in a text (.txt) file with the same name as the img. Each label is in the following format, where x and y are the anchor (center) point of the object.\n",
    "* <object-class-id> \\<x> \\<y> \\<width> \\<height>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and replace labels from source to home directory\n",
    "# Labels\n",
    "\n",
    "# Images\n",
    "orig_images = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\Fish_annotations_based_on_YOLO\\*\\screened_with_fish\\original_images\\*\\*.png\")\n",
    "orig_labels = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\Fish_annotations_based_on_YOLO\\*\\screened_with_fish\\YOLO_bbox_coordinates\\*.txt\")\n",
    "orig_obb = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\Fish_annotations_based_on_YOLO\\*\\screened_with_fish\\YOLO_obb_coordinates\\*.txt\")\n",
    "print(len(orig_images)) # 69831\n",
    "print(len(orig_labels)) # 69831\n",
    "print(len(orig_obb)) # 69831\n",
    "# copy_img_lst_conv_jpg(orig_images_2022, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All labels dataframe with potential avoidance flag\n",
    "# df_20_23_all = generate_splits(img_pth_lst=orig_images, bbox_pths=orig_labels, mer_pths=orig_obb).return_merged()\n",
    "\n",
    "# # Load master label dataframe\n",
    "# master_lbl_df = pd.read_csv(r\"Z:\\__Organized_Directories_InProgress\\Fish_annotations_based_on_YOLO\\YOLO_coordinates_combined_2020_2023_bbox.csv\", index_col=0)\n",
    "# print(master_lbl_df.shape)  # (238028, 10) - with 2019  (231608, 11)\n",
    "\n",
    "# # Add n_fish column to df_20_23_all\n",
    "# df_20_23_alln = df_20_23_all.copy()\n",
    "# nfpi = master_lbl_df.groupby(\"Filename\").size().reset_index(name=\"n_fish\")\n",
    "# df_20_23_alln = df_20_23_alln.merge(nfpi, how=\"left\")\n",
    "# print(df_20_23_alln.year.value_counts())\n",
    "# assert df_20_23_alln.shape[0] == df_20_23_all.shape[0]\n",
    "\n",
    "# df_20_23_alln.to_csv(r\"datasets\\AUV_datasets\\All_Goby_imgs_lbls_pths_n_fish.csv\")\n",
    "'''\n",
    "year\n",
    "2021    29228\n",
    "2020    23339\n",
    "2023     9052\n",
    "2022     8213\n",
    "Name: count, dtype: int64\n",
    "'''\n",
    "\n",
    "df_20_23_alln = pd.read_csv(r\"..\\datasets\\AUV_datasets\\All_Goby_imgs_lbls_pths_n_fish.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20_23_alln[df_20_23_alln.year==2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make master label dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_lbl_df = general.make_master_lbl_df(df_20_23_alln[[\"bbox_path\", \"year\"]]) # (takes 45 min)\n",
    "# master_lbl_df.to_csv(r\"Z:\\__Organized_Directories_InProgress\\Fish_annotations_based_on_YOLO\\YOLO_coordinates_combined_2020_2023_bbox.csv\")\n",
    "master_lbl_df = pd.read_csv(r\"Z:\\__Organized_Directories_InProgress\\Fish_annotations_based_on_YOLO\\YOLO_coordinates_combined_2020_2023_bbox.csv\", index_col=0)\n",
    "master_lbl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a textfile of image list / label list for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general.write_list_txt(lbl_pth_txt, lbl_pths)\n",
    "# general.write_list_txt(img_pth_txt, img_pths) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Master Label Database to MER Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QAQC task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_qaqc_images_plus_label():\n",
    "    year = \"2023\"\n",
    "    qaqc_df = df_20_23_alln[(df_20_23_alln.n_fish>10) & (df_20_23_alln.year==year)][[\"local_path\", \"image_id\", \"bbox_path\", \"year\", \"n_fish\", \"fish_type\"]]\n",
    "    # pth_lst = qaqc_df.local_path\n",
    "    # general.copy_files_lst(pth_lst, dest, overwrite=False)\n",
    "    print(qaqc_df.shape)\n",
    "    dest = f\"datasets\\\\alewife_qaqc\\\\{year}_lbl\"\n",
    "    if not os.path.exists(dest): os.mkdir(dest)\n",
    "    for idx, row in qaqc_df.iterrows():\n",
    "        local_path, image_id, bbox_path, year, n_fish, fish_type = row\n",
    "        lbl_img = generate_annot_imgs.disp_lbl_bbox(local_path, bbox_path)\n",
    "        lbl_img.save(os.path.join(dest,f\"{image_id}_lbl.jpg\")) \n",
    "def make_qaqc_excel(qaqc_df):    \n",
    "    pth_lst = qaqc_df.local_path\n",
    "    path = qaqc_df.image_id.apply(lambda x: f\"{year}\\\\{x}\" )\n",
    "    qaqc_df[\"path\"] = qaqc_df.image_id.apply(lambda x: f\"{year}\\\\{x}.jpg\")\n",
    "    qaqc_df.iloc[:,1:].to_excel(os.path.join(dir,f\"{year}_qaqc.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimimum enclosing rectangles (MER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MER_cord = pd.read_csv(r\"Z:\\__Organized_Directories_InProgress\\Fish_annotations_based_on_YOLO\\_MERR_coordinates_all_years_id_fishtype_unfiltered.csv\", low_memory=False, index_col=0)\n",
    "fish_id_dropped = pd.read_csv(r\"Z:\\__Organized_Directories_InProgress\\Fish_annotations_based_on_YOLO\\fish_id_dropped.csv\", index_col=0)\n",
    "\n",
    "assert set(master_lbl_df.fish_id).difference(MER_cord.fish_id) == set()\n",
    "print(MER_cord.shape) # (231609, 21)\n",
    "MER_cord.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 - 2023 Run 11 Run 12\n",
    "Run 11+ incorperates validation set for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test/Valid Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 11/12\n",
    "# s2019 = generate_splits().sample_df(df_22_23_all, \"2019\", 2000)\n",
    "s2020 = generate_splits().sample_df(df_20_23_alln, \"2020\", 11000)\n",
    "s2021 = generate_splits().sample_df(df_20_23_alln, \"2021\", 11000)\n",
    "s2022 = generate_splits().sample_df(df_20_23_alln, \"2022\", 8212)\n",
    "s2023 = generate_splits().sample_df(df_20_23_alln, \"2023\", 9052)\n",
    "train_df, test_df, valid_df = generate_splits().chunk_split([s2020, s2021, s2022, s2023]) \n",
    "# train_df.to_csv(r\"datasets\\AUV_datasets\\Runs\\run12_png\\train_df.csv\")\n",
    "# valid_df.to_csv(r\"datasets\\AUV_datasets\\Runs\\run12_png\\valid_df.csv\")\n",
    "# test_df.to_csv(r\"datasets\\AUV_datasets\\Runs\\run12_png\\test_df.csv\")\n",
    "\n",
    "# Run 11 Train (32960, 7) valid (4064, 7) test (4176, 7) \n",
    "# Train (31377, 7) valid (3888, 7) test (3968, 7) # run 12 jpg\n",
    "# Train (31400, 8) valid (3888, 8) test (3976, 8) # run 12 png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 13\n",
    "s2020 = generate_splits().sample_df(df_20_23_alln, \"2020\", 9261)\n",
    "s2021 = generate_splits().sample_df(df_20_23_alln, \"2021\", 5105)\n",
    "s2022 = generate_splits().sample_df(df_20_23_alln, \"2022\", 1469)\n",
    "s2023 = generate_splits().sample_df(df_20_23_alln, \"2023\", 976)\n",
    "train_df, test_df, valid_df = generate_splits().chunk_split([s2020, s2021, s2022, s2023]) # Train (31401, 8) valid (3888, 8) test (3976, 8)\n",
    "# Train (13435, 8) valid (1664, 8) test (1712, 8)\n",
    "# train_df.to_csv(r\"datasets\\AUV_datasets\\run13\\train_df.csv\")\n",
    "# valid_df.to_csv(r\"datasets\\AUV_datasets\\run13\\valid_df.csv\")\n",
    "# test_df.to_csv(r\"datasets\\AUV_datasets\\run13\\test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 14 - OBB with 2-class for alewife\n",
    "s2020 = generate_splits().sample_df(df_20_23_alln, \"2020\", 11000)\n",
    "s2021 = generate_splits().sample_df(df_20_23_alln, \"2021\", 11000)\n",
    "s2022 = generate_splits().sample_df(df_20_23_alln, \"2022\", 8196)\n",
    "s2023 = generate_splits().sample_df(df_20_23_alln, \"2023\", 9028)\n",
    "train_df, test_df, valid_df = generate_splits().chunk_split([s2020, s2021, s2022, s2023], tr_frac=0.82, va_frac=0.1, year_splits = 8) \n",
    "alewife_id = list(set(MER_cord.image_id[MER_cord.cls==1]))\n",
    "print(len(alewife_id))\n",
    "print(len(train_df[train_df.image_id.isin(alewife_id)]))\n",
    "print(len(valid_df[valid_df.image_id.isin(alewife_id)]))\n",
    "print(len(test_df[test_df.image_id.isin(alewife_id)]))\n",
    "'''\n",
    "Train (32144, 8) valid (3932, 8) test (3148, 8)\n",
    "62\n",
    "35\n",
    "10\n",
    "13\n",
    "'''\n",
    "# the missing alewife images\n",
    "all_df_id = pd.concat([train_df, valid_df, test_df]).image_id\n",
    "aid = all_df_id[all_df_id.isin(alewife_id)]\n",
    "# set(alewife_id).difference(aid)\n",
    "\n",
    "# train_df.to_csv(r\"datasets\\AUV_datasets\\run14\\train_df.csv\")\n",
    "# valid_df.to_csv(r\"datasets\\AUV_datasets\\run14\\valid_df.csv\")\n",
    "# test_df.to_csv(r\"datasets\\AUV_datasets\\run14\\test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test set by year and copying to folder tree by year\n",
    "root = \"/caldera/projects/usgs/ecosystems/glsc/datasets/run11\"\n",
    "test_df_pth = \"/caldera/projects/usgs/ecosystems/glsc/datasets/run11/test_df.csv\"\n",
    "'''\n",
    "(4176, 7)\n",
    "2020 (1320, 7)\n",
    "2021 (1112, 7)\n",
    "2022 (832, 7)\n",
    "2023 (912, 7)\n",
    "copying 912/912 2023 labels\n",
    "'''\n",
    "def make_set_by_year(test_df_pth, root):\n",
    "    test_df = pd.read_csv(test_df_pth, index_col=0)\n",
    "    years = test_df.year.unique()\n",
    "    lens = []\n",
    "    for year in years:\n",
    "        test_dfyear = test_df[(test_df.year == year)]\n",
    "        lens.append(len(test_dfyear))\n",
    "        generate_splits.cpy_yr_tst(df=test_dfyear, year=year, root=root)   \n",
    "    assert test_df.shape[0] == sum(lens)\n",
    "root = r\"datasets\\AUV_datasets\\Runs\\run12_png\"\n",
    "test_df_pth = r\"datasets\\AUV_datasets\\Runs\\run12_png\\test_df.csv\"\n",
    "# make_set_by_year(test_df_pth, root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
