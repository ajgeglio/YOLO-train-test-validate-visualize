{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), \"src\"))\n",
    "from overlays import Overlays\n",
    "from utils import Utils\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Single images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_run12_meta_nf = pd.read_csv(r\"Z:\\__Organized_Directories_InProgress\\GobyFinderDatasets\\AUV_datasets\\Runs\\run12\\run12_metadata.csv\", index_col=0, low_memory=False)\n",
    "df_run12_meta_nf = df_run12_meta_nf[df_run12_meta_nf.Usability == \"Usable\"]\n",
    "filter = df_run12_meta_nf[(df_run12_meta_nf.n_fish > 10) & (df_run12_meta_nf.imh > 2176)].reset_index(drop=True)\n",
    "print(len(filter))\n",
    "i= 81\n",
    "image = filter.image_path[i]\n",
    "label = filter.label_path[i]\n",
    "Overlays.disp_lbl_bbox(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"D:\\ageglio-1\\gobyfinder_yolov8\\datasets\\AUV_datasets\\run13\\2025_goby_relabel_initial_sample\"\n",
    "id = \"PI_1658096538_886_Iver3098_2424_0\"\n",
    "image = os.path.join(path, \"tiled_images\", id+\".png\")\n",
    "label = os.path.join(path, \"tiled_labels\", id+\".txt\")\n",
    "Overlays.disp_lbl_bbox(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting training data as a check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Utils.read_list_txt(r\"..\\datasets\\AUV_datasets\\run13\\tiled\\validation\\images.txt\")\n",
    "labels = Utils.read_list_txt(r\"..\\datasets\\AUV_datasets\\run13\\tiled\\validation\\labels.txt\")\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched_images, matched_labels = Utils.match_images_to_labels(images, labels)\n",
    "matched_images, matched_labels = images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 321 446 538 1206 1320 1891 2080 2783 3186 3781 4349 4456 5118 5473 6239 - alewife 6412 7410 7887 8292 8364 8665 8846 9085 9958 10508 11178 11429 11436 11863 12445 12502 12579 12983 13096 13160\n",
    "import random\n",
    "i = random.randint(0, len(matched_images))\n",
    "print(i)\n",
    "image = matched_images[i]\n",
    "label = matched_labels[i]\n",
    "plot_img =  Overlays.disp_lbl_bbox(image, label)\n",
    "plot_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting and saving OBB QAQC images for alewife detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_pth = r\"Z:\\__Organized_Directories_InProgress\\Annotated_Images\\2021_LakeMichigan_Annotated_Images\\images\\CI_1625690871_595.png\"\n",
    "years = ['2020', '2021', '2022', '2023']\n",
    "years = [\"2022\"]\n",
    "def plot_alewife_images(years):\n",
    "    for year in years:\n",
    "        img_dir = f\"datasets\\\\AUV_datasets\\\\images\\\\{year}\"\n",
    "        run_dir = f\"test_runs\\\\detect\\\\Run14+-alewife_annot_imgs_{year}\"\n",
    "        lbl_csv = f\"Run14+-alewife_annot_imgs_{year}_Labels.csv\"\n",
    "        score_csv = f\"Run14+-alewife_annot_imgs_{year}_scores.csv\"\n",
    "        lbl_df = pd.read_csv(os.path.join(run_dir, lbl_csv))\n",
    "        scores_df = pd.read_csv(os.path.join(run_dir, score_csv))\n",
    "        new_path = os.path.join(run_dir, f\"{year}_qaqc_images\")\n",
    "        if not os.path.exists(new_path): os.mkdir(new_path)\n",
    "        for im in scores_df.image_id.unique():\n",
    "            im_pth = glob.glob(os.path.join(img_dir, im+\".jpg\"))[0]\n",
    "            Overlays().save_annot_imgs_obb_2(im_pth, lbl_df, scores_df, conf_thresh=0.0, new_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate prediction labels only for LMGS Gopro QAQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# img_pths = general.list_files(\"datasets\\LMBS Goby Photos\", \".jpg\", gopro=True)\n",
    "# new_path = r\"C:\\Users\\ageglio\\ageglio-1\\gobyfinder_yolov8\\inference\\LMBS_Goby_Photos_conf0.05\\lbl_imgs\"\n",
    "# pred_df = pd.read_csv(r\"C:\\Users\\ageglio\\ageglio-1\\gobyfinder_yolov8\\inference\\LMBS_Goby_Photos_conf0.05\\LMBS_Goby_Photos_conf0.05_Yolo_predictions.csv\")\n",
    "# for img_pth in img_pths:\n",
    "#     generate_annot_imgs().save_annot_imgs_pred_only(img_pth, pred_df, new_path, background = \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate annotated images with labels and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.read_csv(r\"test_runs\\detect\\balanced_test_init_assmt\\balanced_test_init_assmt_scores.csv\")\n",
    "simid = sorted(score_df.Filename.unique())\n",
    "img_pths = [r\"Z:\\__Organized_Directories_InProgress\\Fish_annotations_based_on_YOLO\\2020\\screened_with_fish\\original_images\\20200809_001_Iver3069_ABS1\\PI_1596974969_825_Iver3069.png\"]\n",
    "imid = sorted(list(map(lambda x: os.path.basename(x).split(\".\")[0], img_pths)))\n",
    "new_path = r\"test_runs\\detect\\balanced_test_init_assmt\"\n",
    "assert set(imid).intersection(simid) == set(imid), \"img_pths not contained in validation labels\"\n",
    "# for img_pth in img_pths:\n",
    "#     generate_annot_imgs().save_annot_imgs(img_pth, score_df, new_path, conf_thresh=0.36)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['PI_1596974969_825_Iver3069_dt_107','PI_1596974969_825_Iver3069_dt_111','PI_1596974969_825_Iver3069_dt_113','PI_1596974969_825_Iver3069_dt_118','PI_1596974969_825_Iver3069_dt_116','PI_1596974969_825_Iver3069_dt_117','PI_1596974969_825_Iver3069_dt_119',        'PI_1596974969_825_Iver3069_dt_114',        'PI_1596974969_825_Iver3069_dt_101',        'PI_1596974969_825_Iver3069_dt_90',        'PI_1596974969_825_Iver3069_dt_121',        'PI_1596974969_825_Iver3069_dt_72',        'PI_1596974969_825_Iver3069_dt_63',        'PI_1596974969_825_Iver3069_dt_98']\n",
    "names_small = list(map(lambda x: x.split(\"_\")[-1], names))\n",
    "wts = [0.517554073,0.755342822,0.557671634,0.256169483,0.392054384,0.496877683,0.46887362,0.496877683,0.632590853,0.480832252,0.513620776,0.187196292,0.288527773,0.405346274]\n",
    "df = pd.DataFrame(np.c_[names_small, wts], columns=[\"lbl_ID\", \"weight (g)\"])\n",
    "df[\"weight (g)\"] = df[\"weight (g)\"].astype(float).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels for Inference QAQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import generate_labels\n",
    "import os\n",
    "import pandas as pd\n",
    "# def generate_labels_for_inference_QAQC(confidence, img_pths, preds, new_path):\n",
    "#     preds_imgs = preds.Filename.unique()\n",
    "#     filenames = img_pths.apply(lambda x: os.path.basename(x).split(\".\")[0])\n",
    "#     print(len(filenames))\n",
    "#     filenamesp = filenames[filenames.isin(preds_imgs)]    \n",
    "#     img_pths = img_pths[filenames.isin(preds_imgs)]\n",
    "#     print(len(img_pths))\n",
    "#     # img_pths_sample = img_pths.sample(100, random_state=42)\n",
    "#     pred_df = preds[preds.Filename.isin(filenamesp)]\n",
    "#     assert pd.Series(pred_df.Filename.unique()).isin(filenames).all() == True\n",
    "#     if not os.path.exists(new_path):\n",
    "#         os.makedirs(new_path)\n",
    "#     i = 1\n",
    "#     for img_pth in img_pths:\n",
    "#         l = len(img_pths)\n",
    "#         if not os.path.exists(os.path.join(new_path, \"anno_\"+os.path.basename(img_pth))):\n",
    "#             print(\"generating\", i,\"/\",l, end=\"   \\r\")\n",
    "#             generate_annot_imgs().save_annot_imgs_pred_only(confidence, img_pth, pred_df, new_path, background = \"image\")\n",
    "#         i+=1\n",
    "#     print(\"\\n complete\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mussel Control 2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labels_for_inference_QAQC(conf_thresh, img_pths, pred_df, new_path, starting_i):\n",
    "    i = 1\n",
    "    for img_pth in img_pths:\n",
    "        l = len(img_pths)\n",
    "        print(\"generating\", i,\"/\",l, end=\"   \\r\")\n",
    "        if i <= starting_i:\n",
    "            i += 1\n",
    "            return\n",
    "        else:\n",
    "            generate_annot_imgs.save_annot_imgs_pred_only(img_pth, pred_df, new_path, conf_thresh, background = \"image\")\n",
    "            i += 1\n",
    "    print(\"\\n complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.read_csv(r\"Z:\\Proj_Yolo\\Mussel_Control_2024\\Mussel_control_GobyFinder_predictions.csv\", index_col=0)\n",
    "img_pths = glob.glob(r\"G:\\mussel_control_2024\\*.png\")\n",
    "new_path = r\"Z:\\Proj_Yolo\\Mussel_Control_2024\\labeled_images\"\n",
    "conf_thresh = 0.6\n",
    "generate_labels_for_inference_QAQC(conf_thresh, img_pths, pred_df, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020 inference qaqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.28\n",
    "assmt_folder = r\"Z:\\Proj_Yolo\\2020_Yolo_update\\02_2020_Assessment\\2020_Assessment_11-2\"\n",
    "preds = pd.read_csv(os.path.join(assmt_folder, \"2020_Yolo_predictions.csv\"))\n",
    "img_pths = pd.read_csv(os.path.join(assmt_folder, \"meta_2020_usable_goby.csv\"))[\"image_path\"]\n",
    "new_path = r\"Z:\\Proj_Yolo\\Assessment_11-2_imgs\\2020_lbl_imgs\"\n",
    "# samp = generate_labels_for_inference_QAQC(confidence, img_pths, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2021 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.13\n",
    "assmt_folder = r\"Z:\\Proj_Yolo\\2021_Yolo_update\\02_2021_Assessment\\2021_Assessment_11-2\"\n",
    "img_pths = pd.read_csv(os.path.join(assmt_folder, \"meta_2021_usable_goby.csv\"))[\"image_path\"]\n",
    "preds = pd.read_csv(os.path.join(assmt_folder, \"2021_Yolo_predictions.csv\"))\n",
    "new_path = r\"Z:\\Proj_Yolo\\Assessment_11-2_imgs\\2021_lbl_imgs\"\n",
    "# generate_labels_for_inference_QAQC(confidence, img_pths, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.11\n",
    "assmt_folder = r\"Z:\\Proj_Yolo\\2022_Yolo_update\\02_2022_Assessment\\2022_Assessment_11-2\"\n",
    "img_pths = pd.read_csv(os.path.join(assmt_folder, \"meta_2022_usable_goby.csv\"))[\"image_path\"]\n",
    "preds = pd.read_csv(os.path.join(assmt_folder, \"2022_Yolo_predictions.csv\"))\n",
    "new_path = r\"Z:\\Proj_Yolo\\Assessment_11-2_imgs\\2022_lbl_imgs\"\n",
    "# generate_labels_for_inference_QAQC(confidence, img_pths, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.10\n",
    "assmt_folder = r\"Z:\\Proj_Yolo\\2023_Yolo_update\\02_2023_Assessment\\2023_Assessment_11-2\"\n",
    "img_pths = pd.read_csv(os.path.join(assmt_folder, \"meta_2023_usable_goby.csv\"))[\"image_path\"]\n",
    "preds = pd.read_csv(os.path.join(assmt_folder, \"2023_Yolo_predictions.csv\"))\n",
    "new_path = r\"Z:\\Proj_Yolo\\Assessment_11-2_imgs\\2023_lbl_imgs\"\n",
    "# generate_labels_for_inference_QAQC(confidence, img_pths, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yolov8v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
