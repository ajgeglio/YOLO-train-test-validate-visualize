{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746fb750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir, \"src\")))\n",
    "from utils import Utils\n",
    "from labelUtils import LabelUtils\n",
    "from reportFunctions import Reports\n",
    "import matplotlib.pyplot as plt\n",
    "from overlayFunctions import Overlays\n",
    "from utils import Utils\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a48d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usable Abiss1 images: 33356\n",
      "usable Abiss2 images: 13549\n"
     ]
    }
   ],
   "source": [
    "# filter for images with n_fish >= n images\n",
    "# df_run12_meta_nf = pd.read_csv(r\"Z:\\__Organized_Directories_InProgress\\GobyFinderDatasets\\AUV_datasets\\runs\\run12\\run12_metadata.csv\", index_col=0, low_memory=False)\n",
    "all_meta_nf = pd.read_csv(r\"Z:\\__AdvancedTechnologyBackup\\07_Database\\MetadataCombined\\all_annotated_meta_splits_filtered_20251030.csv\", index_col=0, low_memory=False)\n",
    "df_abs2_meta_nf = all_meta_nf[(all_meta_nf.n_fish >= 0)  & (all_meta_nf.imh > 2176)]\n",
    "df_abs1_meta_nf = all_meta_nf[(all_meta_nf.n_fish >= 0)  & (all_meta_nf.imh == 2176)]\n",
    "abiss2_len = len(df_abs2_meta_nf) \n",
    "abiss1_len = len(df_abs1_meta_nf)  \n",
    "# export_paths(df_abs1_meta_nf[df_abs1_meta_nf.split == \"test\"], run13_folder, subfolder=\"abiss1_test\")\n",
    "print(\"usable Abiss1 images:\", abiss1_len)\n",
    "print(\"usable Abiss2 images:\", abiss2_len) #usable Abiss2 images: 14225\n",
    "few_fish_df = df_abs2_meta_nf[(df_abs2_meta_nf.n_fish < 2)]\n",
    "new_path = r\"Z:\\__Organized_Directories_InProgress\\GobyFinderDatasets\\AUV_datasets\\one_fish\\images\"\n",
    "output_dir = r\"Z:\\__Organized_Directories_InProgress\\GobyFinderDatasets\\AUV_datasets\\one_fish\\overlays\"\n",
    "# Overlays.plot_label_overlays(few_fish_df.image_path, few_fish_df.label_path, output_dir, overwrite=False)\n",
    "# usable Abiss1 images: 33356\n",
    "# usable Abiss2 images: 13549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d77359cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiles_paths_from_tile_names(TILE_NAMES, BASE_DIR):\n",
    "    all_tiled_image_paths, all_tiled_label_paths = Utils.get_all_img_lbl_pths(BASE_DIR)\n",
    "    img_path_map_no_ext = {os.path.basename(p).split(\".\")[0]: p for p in all_tiled_image_paths}\n",
    "    tiled_im_no_ext = list(map(lambda x: x.split(\".\")[0], TILE_NAMES))\n",
    "    batch_tiled_im_fp = [img_path_map_no_ext[bn] for bn in tiled_im_no_ext if bn in img_path_map_no_ext]\n",
    "    return sorted(batch_tiled_im_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "569a75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiles_paths_from_batch_dir(BATCH_DIR, BASE_DIR, SPLITS):\n",
    "    all_tiled_image_paths, all_tiled_label_paths = Utils.get_all_img_lbl_pths(BASE_DIR, SPLITS)\n",
    "    batch_tiled_im = os.listdir(BATCH_DIR+\"\\\\\"+\"images\")\n",
    "    batch_tiled_lb = os.listdir(BATCH_DIR+\"\\\\\"+\"labels\")\n",
    "    batch_tiled_im_no_ext = list(map(lambda x: x.split(\".\")[0], batch_tiled_im))\n",
    "    batch_tiled_lb_no_ext = list(map(lambda x: x.split(\".\")[0], batch_tiled_lb))\n",
    "\n",
    "    # --- Refactored & Completed Assignments ---\n",
    "\n",
    "    # 1. Create basename-to-fullpath dictionaries (The key step for efficient lookup)\n",
    "    # Note: zip is often cleaner than map(lambda...) for pairing elements.\n",
    "    img_path_map_no_ext = {os.path.basename(p).split(\".\")[0]: p for p in all_tiled_image_paths}\n",
    "    lbl_path_map_no_ext = {os.path.basename(p).split(\".\")[0]: p for p in all_tiled_label_paths}\n",
    "\n",
    "    # 2. Use list comprehensions to look up the full paths using the batch basenames\n",
    "    # This is much faster than searching a list repeatedly.\n",
    "\n",
    "    batch_tiled_im_fp = [img_path_map_no_ext[bn] for bn in batch_tiled_im_no_ext if bn in img_path_map_no_ext]\n",
    "    batch_tiled_lb_fp = [lbl_path_map_no_ext[bn] for bn in batch_tiled_lb_no_ext if bn in lbl_path_map_no_ext]\n",
    "\n",
    "    # --- Verification (Optional) ---\n",
    "    print(f\"Total full paths found for images in batch: {len(batch_tiled_im_fp)}\")\n",
    "    print(f\"Total full paths found for labels in batch: {len(batch_tiled_lb_fp)}\")\n",
    "    # assert len(batch_tiled_im_fp) == len(batch_tiled_im), \"Some image files not found in the master list.\"\n",
    "    # assert len(batch_tiled_lb_fp) == len(batch_tiled_lb), \"Some label files not found in the master list.\"\n",
    "    return sorted(batch_tiled_im_fp), sorted(batch_tiled_lb_fp)\n",
    "\n",
    "# BATCH_DIR = r\"Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\transects\\20240804_001_Iver3069_ABS2\\20240804_001_Iver3069_ABS2_batch_00\"\n",
    "# BASE_DIR = r\"Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\transects\\20240804_001_Iver3069_ABS2\"\n",
    "# batch_tiled_im_fp, batch_tiled_lb_fp = get_tiles_paths_from_batch_dir(BATCH_DIR = BATCH_DIR, BASE_DIR = BASE_DIR, SPLITS = None)\n",
    "\n",
    "# Utils.write_list_txt(sorted(batch_tiled_im_fp), BATCH_DIR+\"\\\\\"+\"images.txt\")\n",
    "# Utils.write_list_txt(sorted(batch_tiled_lb_fp), BATCH_DIR+\"\\\\\"+\"labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6154d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_paths_from_tiled_images(tiled_images):\n",
    "    batch_set = set(map(lambda x: Utils.convert_tile_img_pth_to_basename(x), tiled_images))\n",
    "    all_full_imgs = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\GobyFinderDatasets\\AUV_datasets\\full\\images\\*.png\")\n",
    "    all_full_lbls = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\GobyFinderDatasets\\AUV_datasets\\full\\labels\\*.txt\")\n",
    "    print(\"full images\", len(all_full_lbls))\n",
    "    assert len(all_full_imgs) == len(all_full_lbls)\n",
    "    img_path_map_no_ext = {os.path.basename(p).split(\".\")[0]: p for p in all_full_imgs}\n",
    "    lbl_path_map_no_ext = {os.path.basename(p).split(\".\")[0]: p for p in all_full_lbls}\n",
    "    batch_full_im_fp = [img_path_map_no_ext[bn] for bn in batch_set if bn in img_path_map_no_ext]\n",
    "    batch_full_lb_fp = [lbl_path_map_no_ext[bn] for bn in batch_set if bn in lbl_path_map_no_ext]\n",
    "    assert len(batch_full_im_fp) == len(batch_full_lb_fp), \"number of images and labels do not match\"\n",
    "    print(\"full image paths from tiled paths\", len(batch_full_lb_fp))\n",
    "    return batch_full_im_fp, batch_full_lb_fp\n",
    "    \n",
    "# batch_full_im_fp, batch_full_lb_fp = get_full_paths_from_tiled_images(batch_tiled_im_fp)   \n",
    "# Utils.write_list_txt(batch_full_im_fp, r\"Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\relabel\\2025_goby_relabel_batch_01\\full\\images.txt\")\n",
    "# Utils.write_list_txt(batch_full_lb_fp, r\"Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\relabel\\2025_goby_relabel_batch_01\\full\\labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1d1ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conf_batches(scores_df: pd.DataFrame, pred_df: pd.DataFrame, output_directory: str, batch_size: int = 1500):\n",
    "    \"\"\"\n",
    "    Bins the dataframe samples into batches of EXACTLY 'batch_size' unique images (except the final batch).\n",
    "    \"\"\"\n",
    "    print(f\"Starting batch creation for {len(scores_df['Filename'].unique())} unique images based on scores_df...\")\n",
    "    \n",
    "    # 1. Sort the scores DataFrame by 'conf'\n",
    "    df_scored_sorted = scores_df.sort_values(by='conf', ascending=False)\n",
    "    \n",
    "    # Get the unique image filenames in the sorted order as a NumPy array for clean splitting\n",
    "    unique_filenames_array = df_scored_sorted['Filename'].drop_duplicates().to_numpy()\n",
    "    num_unique_images = len(unique_filenames_array)\n",
    "    \n",
    "    # 2. Determine batch splits\n",
    "    # Calculate the exact number of batches required\n",
    "    num_batches = int(np.ceil(num_unique_images / batch_size))\n",
    "\n",
    "    # --- CORE FIX ---\n",
    "    # Use array_split to divide the unique_filenames_array into 'num_batches' parts.\n",
    "    # This guarantees that the first (N-1) parts are as close to 'batch_size' as possible.\n",
    "    # When num_batches is calculated based on batch_size, this ensures the size target.\n",
    "    batch_filename_splits = np.array_split(unique_filenames_array, num_batches)\n",
    "    # ----------------\n",
    "    \n",
    "    base_output_path = Path(output_directory)\n",
    "    \n",
    "    # 3. Iterate through batches\n",
    "    for i, batch_filenames in enumerate(batch_filename_splits):\n",
    "        \n",
    "        # 'batch_filenames' is now an array containing the exact filenames for this batch.\n",
    "        \n",
    "        # Select the hard negative rows for the batch for scoring/metadata\n",
    "        scores_df_isin = df_scored_sorted[df_scored_sorted['Filename'].isin(batch_filenames)].copy()\n",
    "        \n",
    "        # Select ALL prediction rows for the batch for YOLO label generation\n",
    "        batch_df_isin = pred_df[pred_df['Filename'].isin(batch_filenames)].copy()\n",
    "        \n",
    "        # 4. Determine confidence range of the FP for naming\n",
    "        conf_min = scores_df_isin['conf'].min()\n",
    "        conf_max = scores_df_isin['conf'].max()\n",
    "        \n",
    "        # 5. Create batch output directory\n",
    "        folder_name = f\"HNM_batch_{i+1:03d}_conf_{conf_max:.2f}\"\n",
    "        batch_output_path = base_output_path / folder_name\n",
    "        os.makedirs(batch_output_path, exist_ok=True)\n",
    "\n",
    "        # Save the hard negative dataframe for this specific batch\n",
    "        scores_df_isin.to_csv(os.path.join(batch_output_path, \"scores_df.csv\"), index=False)\n",
    "        \n",
    "        # 6. Save image list file (images.txt)\n",
    "        image_paths = batch_df_isin['tile_path'].unique().tolist()\n",
    "        \n",
    "        image_list_filename = batch_output_path / \"images.txt\"\n",
    "        Utils.write_list_txt(image_paths, str(image_list_filename))\n",
    "        \n",
    "        # 7. Save YOLO labels for the batch (assuming LabelUtils is fixed to accept confidence_thresh)\n",
    "        LabelUtils.convert_predict_df_to_yolo_labels(batch_df_isin, confidence_thresh=0.25, batch_output_dir=str(batch_output_path))\n",
    "        \n",
    "        # Print actual size of the batch\n",
    "        print(f\"✅ Batch {i+1}/{num_batches} (Images: {len(image_paths)}, Conf Range: [{conf_min:.2f}, {conf_max:.2f}]) created in: {batch_output_path}\", end=\"  \\r\")\n",
    "\n",
    "    print(\"\\nBatch creation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9467323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found in D:\\datasets\\tiled: 277902\n",
      "Total labels found: 277902\n",
      "n fp objects 62692\n",
      "n fp tiles 43386\n",
      "n fp full imgs 11766\n"
     ]
    }
   ],
   "source": [
    "# Get HNM tiles - Tiles with False positive predictions with high confidence\n",
    "thresh = 0.1\n",
    "run13_HNM_test_score = pd.read_csv(r\"D:\\ageglio-1\\gobyfinder_yolov8\\output\\test_runs\\run13-tile-test\\scores.csv\", index_col=0)\n",
    "\n",
    "run13_HNM_test_score_fp = run13_HNM_test_score[run13_HNM_test_score.fp==1]\n",
    "HNM_fp_objects = run13_HNM_test_score_fp[run13_HNM_test_score_fp.conf>=thresh].copy()\n",
    "HNM_fp_tiles = HNM_fp_objects.Filename.unique()\n",
    "HNM_fp_full_images = HNM_fp_objects.Filename.apply(lambda x: Utils.convert_tile_img_pth_to_basename(x)).unique()\n",
    "\n",
    "pred_df = pd.read_csv(r\"D:\\ageglio-1\\gobyfinder_yolov8\\output\\test_runs\\run13-tile-test\\predictions.csv\", index_col=0)\n",
    "pred_df_filt = pred_df.copy()\n",
    "pred_df_filt[\"tile_path\"] = get_tiles_paths_from_tile_names(pred_df_filt.Filename, BASE_DIR= r\"D:\\datasets\\tiled\")\n",
    "assert pred_df_filt.tile_path.notna().all()\n",
    "\n",
    "print(\"n fp objects\", len(HNM_fp_objects))\n",
    "print(\"n fp tiles\", len(HNM_fp_tiles))\n",
    "print(\"n fp full imgs\", len(HNM_fp_full_images))\n",
    "\n",
    "assert len(pred_df_filt[pred_df_filt.Filename.isin(HNM_fp_tiles)].Filename.unique()) == len(HNM_fp_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beb79a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch creation for 43386 unique images based on scores_df...\n",
      "   Generated 1497 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_001_conf_0.83\\yolo_labels' directory.\n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 1497 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_002_conf_0.58\\yolo_labels' directory. \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 1496 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_003_conf_0.52\\yolo_labels' directory. \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 1496 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_004_conf_0.48\\yolo_labels' directory. \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 1496 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_005_conf_0.45\\yolo_labels' directory. \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 1496 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_006_conf_0.42\\yolo_labels' directory. \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 1496 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_007_conf_0.39\\yolo_labels' directory. \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 1496 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_008_conf_0.37\\yolo_labels' directory. \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 1496 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_009_conf_0.34\\yolo_labels' directory. \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 1496 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_010_conf_0.32\\yolo_labels' directory. \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 1496 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_011_conf_0.30\\yolo_labels' directory.  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 1496 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_012_conf_0.29\\yolo_labels' directory.  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 1496 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_013_conf_0.27\\yolo_labels' directory.  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 604 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_014_conf_0.25\\yolo_labels' directory.7  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 426 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_015_conf_0.24\\yolo_labels' directory.5  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 426 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_016_conf_0.22\\yolo_labels' directory.4  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 444 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_017_conf_0.21\\yolo_labels' directory.2  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 391 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_018_conf_0.20\\yolo_labels' directory.1  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 418 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_019_conf_0.19\\yolo_labels' directory.0  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 409 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_020_conf_0.18\\yolo_labels' directory.9  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 432 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_021_conf_0.17\\yolo_labels' directory.8  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 383 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_022_conf_0.16\\yolo_labels' directory.7  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 401 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_023_conf_0.15\\yolo_labels' directory.6  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 424 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_024_conf_0.14\\yolo_labels' directory.5  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 401 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_025_conf_0.13\\yolo_labels' directory.4  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 414 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_026_conf_0.12\\yolo_labels' directory.3  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 371 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_027_conf_0.12\\yolo_labels' directory.2  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 401 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_028_conf_0.11\\yolo_labels' directory.2  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "   Generated 424 YOLO label files in the 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_029_conf_0.11\\yolo_labels' directory.1  \n",
      "   Total bounding boxes written (conf >= 0.25): Series([], dtype: float64)\n",
      "✅ Batch 29/29 (Images: 1496, Conf Range: [0.10, 0.11]) created in: Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_029_conf_0.11  \n",
      "Batch creation complete.\n"
     ]
    }
   ],
   "source": [
    "output_dir = r\"Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\"\n",
    "create_conf_batches(HNM_fp_objects, pred_df_filt, output_dir, batch_size=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "572a2c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping content of 'yolo_labels' into 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_001_conf_0.83\\yolo_labels.zip'\n",
      "Successfully created: Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_001_conf_0.83\\yolo_labels.zip\n",
      "Zipping content of 'yolo_labels' into 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_002_conf_0.58\\yolo_labels.zip'\n",
      "Successfully created: Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_002_conf_0.58\\yolo_labels.zip\n",
      "Zipping content of 'yolo_labels' into 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_003_conf_0.52\\yolo_labels.zip'\n",
      "Successfully created: Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_003_conf_0.52\\yolo_labels.zip\n",
      "Zipping content of 'yolo_labels' into 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_004_conf_0.48\\yolo_labels.zip'\n",
      "Successfully created: Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_004_conf_0.48\\yolo_labels.zip\n",
      "Zipping content of 'yolo_labels' into 'Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_005_conf_0.45\\yolo_labels.zip'\n",
      "Successfully created: Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_005_conf_0.45\\yolo_labels.zip\n"
     ]
    }
   ],
   "source": [
    "## copy the images over\n",
    "def zip_batch_labels(batch_folder):\n",
    "    lbl_folder = os.path.join(batch_folder, \"yolo_labels\")\n",
    "    Utils.zip_folder(lbl_folder)\n",
    "\n",
    "def copy_zip_batch_images(batch_folder):\n",
    "    images = Utils.read_list_txt(os.path.join(batch_folder, \"images.txt\"))\n",
    "    img_folder = os.path.join(batch_folder, \"images\")\n",
    "    os.makedirs(img_folder, exist_ok=True)\n",
    "    Utils.copy_files_lst(images, img_folder)\n",
    "    # assert len(os.listdir(img_folder)) == len(os.listdir(lbl_folder))\n",
    "    Utils.zip_folder(img_folder)\n",
    "\n",
    "batch_folders = [\n",
    "    r\"Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_001_conf_0.83\",\n",
    "    r\"Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_002_conf_0.58\",\n",
    "    r\"Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_003_conf_0.52\",\n",
    "    r\"Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_004_conf_0.48\",\n",
    "    r\"Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\HNM\\HNM_batch_005_conf_0.45\"\n",
    "]\n",
    "for img_txt in batch_folders:\n",
    "    zip_batch_labels(img_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1834eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_batch_paths_tile_relabel(all_images_df):\n",
    "    \"\"\"\n",
    "    Exports full and tiled image/label paths for relabeling batches.\n",
    "    Prevents resampling and re-exporting of batches that already have an 'images.txt' list.\n",
    "    \"\"\"\n",
    "    # --- Setup ---\n",
    "    all_tiled_image_paths, all_tiled_label_paths = Utils.get_all_tiled_img_lbl_pths()\n",
    "    \n",
    "    # Define constants\n",
    "    BATCH_SIZE = 100\n",
    "    innodata_update = r\"Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\relabel\"\n",
    "    \n",
    "    # --- Step 1: Handle the Initial Sample (Pre-existing/Fixed List) ---\n",
    "    name_initial = \"2025_goby_relabel_initial_sample\"\n",
    "    initial_full_dir = os.path.join(innodata_update, name_initial, \"full\")\n",
    "    initial_images_list_path = os.path.join(initial_full_dir, \"images.txt\")\n",
    "\n",
    "    try:\n",
    "        initial_images = Utils.read_list_txt(initial_images_list_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Initial sample list not found at {initial_images_list_path}. Exiting.\")\n",
    "        return # Exit if the baseline list is missing\n",
    "\n",
    "    # Get basenames of initial sample images\n",
    "    initial_bn = {os.path.basename(x).split(\".\")[0] for x in initial_images}\n",
    "    \n",
    "    # Remove initial sample images from the pool\n",
    "    initial_indices = all_images_df[all_images_df.Filename.isin(initial_bn)].index\n",
    "    remaining_images_df = all_images_df.drop(initial_indices)\n",
    "\n",
    "    # --- Step 2: Process Subsequent Batches (Repeatable Random Samples) ---\n",
    "    batch_number = 1\n",
    "    total_new_batches = 0\n",
    "    \n",
    "    while len(remaining_images_df) > 0:\n",
    "        name = f\"2025_goby_relabel_batch_{batch_number:02d}\"\n",
    "        \n",
    "        # Define paths for the current batch's tiled output\n",
    "        tile_img_dir = os.path.join(innodata_update, name, \"tiled\", \"images\")\n",
    "        if os.path.exists(tile_img_dir):\n",
    "            filenames = os.listdir(tile_img_dir)\n",
    "            tiled_imgs = [f for f in filenames if f.endswith(\".png\") or f.endswith(\".jpg\")]\n",
    "            # Check if the list for this batch already exists (AVOIDS RESAMPLING)\n",
    "            if len(tiled_imgs) > 0:\n",
    "                existing_tiled_txt = os.path.join(innodata_update, name, \"tiled\", \"images.txt\")\n",
    "                print(f\"Skipping {name}: {len(tiled_imgs)} already exist. Removing images from remaining pool.\")\n",
    "                # integrity check\n",
    "                Utils.check_txt_file_vs_images(existing_tiled_txt, tile_img_dir)\n",
    "                # remove its contents from remaining_images_df\n",
    "                # Find the corresponding full image basenames to drop from the DataFrame\n",
    "                existing_basenames = list(map(lambda x: Utils.convert_tile_img_pth_to_basename(x), existing_tiled_txt))\n",
    "\n",
    "                # --- Robust Dropping Logic ---\n",
    "                # We must use the *full image* names that were sampled to create this batch.\n",
    "                \n",
    "                try:\n",
    "                    sampled_indices = remaining_images_df[\n",
    "                        remaining_images_df.Filename.isin(existing_basenames)\n",
    "                    ].index\n",
    "                    \n",
    "                    remaining_images_df.drop(sampled_indices, inplace=True)\n",
    "                    \n",
    "                except FileNotFoundError:\n",
    "                    print(f\"WARNING: Full list for {name} not found. Could not skip batch.\")\n",
    "                    break # Stop if we can't reliably skip the batch\n",
    "                # ---------------------------\n",
    "            \n",
    "        else:\n",
    "            # --- Create a New Batch ---\n",
    "            total_new_batches += 1\n",
    "            print(f\"Creating new batch: {name}\")\n",
    "            \n",
    "            current_batch_size = min(BATCH_SIZE, len(remaining_images_df))\n",
    "            \n",
    "            # Use random_state based on batch number to make the sample repeatable across runs\n",
    "            # Since the user asked it NOT to change, we must use random_state.\n",
    "            subset = remaining_images_df.sample(n=current_batch_size, random_state=batch_number)\n",
    "            \n",
    "            # Define output paths\n",
    "            full_dir = os.path.join(innodata_update, name, \"full\")\n",
    "            os.makedirs(full_dir, exist_ok=True)\n",
    "            # Export the current sample batch (Full Images)\n",
    "            Utils.write_list_txt(subset.image_path.values , os.path.join(full_dir, \"images.txt\"))\n",
    "            Utils.write_list_txt(subset.label_path.values , os.path.join(full_dir, \"labels.txt\"))\n",
    "            \n",
    "            # List and Export the Tiled Images for this subset\n",
    "            tiled_images, tiled_labels = Utils.list_tiled_set(\n",
    "                subset.Filename.values, all_tiled_image_paths, all_tiled_label_paths\n",
    "            )\n",
    "            tile_dir = os.path.join(innodata_update, name, \"tiled\")\n",
    "            os.makedirs(tile_dir, exist_ok=True)\n",
    "            Utils.write_list_txt(tiled_images , os.path.join(tile_dir, \"images.txt\"))\n",
    "            Utils.write_list_txt(tiled_labels , os.path.join(tile_dir, \"labels.txt\"))\n",
    "            # CRITICAL: Remove the sampled subset from the remaining pool\n",
    "            remaining_images_df.drop(subset.index, inplace=True)\n",
    "            \n",
    "        # Increment the batch counter\n",
    "        batch_number += 1\n",
    "\n",
    "    print(f\"Total batches checked: {batch_number - 1}\")\n",
    "    print(f\"Total NEW batches created: {total_new_batches}\")\n",
    "\n",
    "# all_images_df = df_abs2_meta_nf[(df_abs2_meta_nf.n_fish >= 2)].copy()\n",
    "# all_images_df.shape\n",
    "# export_batch_paths_tile_relabel(all_images_df)\n",
    "\n",
    "\n",
    "# # Copy Batches\n",
    "# def copy_tiled_relabel_batch(batch = \"batch_01\"): # Change this to the desired batch number\n",
    "#     path = f\"D:\\\\ageglio-1\\\\gobyfinder_yolov8\\\\datasets\\\\AUV_datasets\\\\innodata_updates\\\\2025_goby_relabel_{batch}\\\\tiled\"\n",
    "#     images, labels = Utils.read_list_txt(os.path.join(path, \"images.txt\")), Utils.read_list_txt(os.path.join(path, \"labels.txt\"))\n",
    "#     img_folder, lbl_folder = os.path.join(path, \"images\"), os.path.join(path, \"labels\")\n",
    "#     Utils.copy_files_lst(images, img_folder)\n",
    "#     Utils.copy_files_lst(labels, lbl_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b9a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_subsampled_transect_tiled_images_labels_with_objects_for_labeling(collect_id, run_copy=True):\n",
    "    # assuming the collect_id inference run is stored locally\n",
    "    all_tiled_image_paths, all_tiled_label_paths = glob.glob(f\"..\\\\output\\\\inference\\\\{collect_id}\\\\tiled\\\\images\\\\*.png\"), glob.glob(f\"..\\\\output\\\\inference\\\\{collect_id}\\\\tiled\\\\labels\\\\*.txt\")\n",
    "    print(len(all_tiled_image_paths), len(all_tiled_label_paths))\n",
    "    assert len(all_tiled_image_paths) == len(all_tiled_label_paths), \"Mismatch between image and label counts.\"\n",
    "    full_imgs = Utils.read_list_txt(f\"..\\\\output\\\\transects\\\\{collect_id}\\\\subsampled_images_0.3\\\\images.txt\")\n",
    "    tiled_images, tiled_labels  = Utils.list_tiled_set(full_imgs, all_tiled_image_paths, all_tiled_label_paths)\n",
    "    assert len(tiled_images) > 0, \"No tiled images found\"\n",
    "    assert len(tiled_images) == len(tiled_labels), \"Mismatch between number of images and labels\"\n",
    "    print(f\"Number of tiled images from full_imgs: {len(tiled_images)}\")\n",
    "    pd.Series(tiled_images).to_csv(f\"..\\\\output\\\\inference\\\\{collect_id}\\\\tiled\\\\selected_tiled_images.csv\", header=False, index=False)\n",
    "    pd.Series(tiled_labels).to_csv(f\"..\\\\output\\\\inference\\\\{collect_id}\\\\tiled\\\\selected_tiled_labels.csv\", header=False, index=False)\n",
    "    # Write the tiled labels to the dataset folder if they are not empty\n",
    "    innodata_project_folder = f\"Z:\\\\__AdvancedTechnologyBackup\\\\04_ProjectData\\\\Innodata_2025\\\\Goby\\\\transects\\\\{collect_id}\"\n",
    "    img_folder = f\"{innodata_project_folder}\\\\images\"\n",
    "    lbl_folder = f\"{innodata_project_folder}\\\\labels\"\n",
    "    if not os.path.exists(img_folder):\n",
    "        os.makedirs(img_folder)\n",
    "    if not os.path.exists(lbl_folder):\n",
    "        os.makedirs(lbl_folder)\n",
    "    for img, lbl in tqdm(zip(tiled_images, tiled_labels)):\n",
    "        if os.path.exists(lbl) and os.path.getsize(lbl) > 0:\n",
    "            shutil.copy2(lbl, lbl_folder)\n",
    "            shutil.copy2(img, img_folder)\n",
    "# tranect tiling and preping for labeling\n",
    "collect_id = \"20240618_001_Iver3069_ABS2\"\n",
    "# collect_id = \"20240804_001_Iver3069_ABS2\"\n",
    "# copy_subsampled_transect_tiled_images_labels_with_objects_for_labeling(collect_id, run_copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739603b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_batch_paths_tile_transect(collect_id):\n",
    "    \"\"\"\n",
    "    Exports tiled image/label paths for transect batches.\n",
    "    Prevents resampling of transects that already have an export directory.\n",
    "    Samples by full image basename to ensure all tiles for a full image stay together.\n",
    "    \"\"\"\n",
    "    # Define constants\n",
    "    BATCH_SIZE = 100\n",
    "    transect_update = f\"Z:\\\\__AdvancedTechnologyBackup\\\\04_ProjectData\\\\Innodata_2025\\\\Goby\\\\transects\\\\{collect_id}\"\n",
    "\n",
    "    # Step 1: Create a DataFrame with ALL existing TILE paths\n",
    "    # Note: Use os.path.join for robust path construction in glob\n",
    "    base_dir = os.path.join(transect_update, \"images\")\n",
    "    all_image_tiles = glob.glob(os.path.join(base_dir, \"*.png\"))\n",
    "    all_label_tiles = glob.glob(os.path.join(transect_update, \"labels\", \"*.txt\"))\n",
    "    \n",
    "    # Check for empty data before proceeding\n",
    "    if not all_image_tiles or not all_label_tiles:\n",
    "        print(f\"No tiled data found for {collect_id}. Exiting.\")\n",
    "        return 0\n",
    "\n",
    "    df = pd.DataFrame(np.c_[all_image_tiles, all_label_tiles], columns=[\"image_path\", \"label_path\"])\n",
    "    \n",
    "    # CRITICAL: Extract the 'Full Image Basename' from the tile label path\n",
    "    # Assuming tile paths look like 'full_image_name_x000_y000.txt'\n",
    "    df['basename'] = df.label_path.apply(lambda x: os.path.basename(x).rsplit('_', 2)[0])\n",
    "    \n",
    "    # The pool of images to sample from is the UNIQUE full image basenames\n",
    "    # Use tolist() and convert back to Series later for easier indexing/sampling\n",
    "    unbatched_basenames_list = df['basename'].unique().tolist()\n",
    "    unbatched_basenames = pd.Series(unbatched_basenames_list)\n",
    "\n",
    "    # Now, we proceed with the batching by basename\n",
    "    batch_number = 0\n",
    "    total_new_batches = 0\n",
    "    total_tiles = 0\n",
    "    \n",
    "    while len(unbatched_basenames) > 0:\n",
    "        name = f\"{collect_id}_batch_{batch_number:02d}\"\n",
    "        transect_path = os.path.join(transect_update, name)\n",
    "        \n",
    "        # --- Skipping Logic ---\n",
    "        images_txt_path = os.path.join(transect_path, \"images.txt\")\n",
    "        if os.path.exists(images_txt_path):\n",
    "            print(f\"Skipping existing batch: {name}\")\n",
    "            \n",
    "            # Read the list of TILED images that were exported\n",
    "            # Assumes Utils.read_list_txt reads the contents of the file\n",
    "            exported_tiled_paths = Utils.read_list_txt(images_txt_path)\n",
    "            total_tiles += len(exported_tiled_paths)\n",
    "            print(f\"Number of tiled images in existing batch: {len(exported_tiled_paths)}\")\n",
    "            # Convert the tiled paths back to their full image basenames\n",
    "            # Assuming Utils.convert_tile_img_pth_to_basename extracts the full image basename\n",
    "            # e.g., converts 'path/to/img_x000_y000.png' to 'img'\n",
    "            exported_basenames = {Utils.convert_tile_img_pth_to_basename(x) for x in exported_tiled_paths}\n",
    "            print(f\"Number of unique basenames in existing batch: {len(exported_basenames)}\")\n",
    "            # Filter the unbatched pool to remove the basenames that are already in this batch\n",
    "            # Convert Series to list/set for difference, then back to Series for sampling\n",
    "            remaining_basenames_set = set(unbatched_basenames.tolist()).difference(exported_basenames)\n",
    "            unbatched_basenames = pd.Series(list(remaining_basenames_set)) # Restore as Series\n",
    "            \n",
    "            batch_number += 1\n",
    "            continue # Go to the next loop iteration (next batch number)\n",
    "            \n",
    "        # --- Create a New Batch ---\n",
    "        else:\n",
    "            total_new_batches += 1\n",
    "            print(f\"Creating new batch: {name}\")\n",
    "            \n",
    "            current_batch_size = min(BATCH_SIZE, len(unbatched_basenames))\n",
    "\n",
    "            # Sample the unique full image basenames from the remaining pool\n",
    "            # Use random_state=batch_number to make the sample repeatable for this batch number\n",
    "            # but only if you want repeatability. The prompt said \"Do NOT set random_state\" \n",
    "            # for different random samples, so we'll remove it.\n",
    "            # Fix: Since unbatched_basenames is a Series of the BASENAMES, sampling works\n",
    "            # Sample by position (frac=None) since index might be arbitrary\n",
    "            subset_basenames = unbatched_basenames.sample(\n",
    "                n=current_batch_size, random_state=None, replace=False\n",
    "            ) \n",
    "            print(f\"Sampled {len(subset_basenames)} basenames for new batch.\")\n",
    "            # Get ALL tile paths associated with the sampled basenames\n",
    "            subset_df = df[df['basename'].isin(subset_basenames.tolist())]\n",
    "            print(f\"Number of TILE images/labels in new batch: {len(subset_df)}\")\n",
    "            total_tiles += len(subset_df)\n",
    "            # Export the list of TILE paths\n",
    "            os.makedirs(transect_path, exist_ok=True)\n",
    "            Utils.write_list_txt(subset_df.image_path.tolist(), os.path.join(transect_path, \"images.txt\"))\n",
    "            Utils.write_list_txt(subset_df.label_path.tolist(), os.path.join(transect_path, \"labels.txt\"))\n",
    "            \n",
    "            # CRITICAL: Remove the sampled basenames from the remaining pool for the next iteration\n",
    "            remaining_basenames_set = set(unbatched_basenames.tolist()).difference(set(subset_basenames.tolist()))\n",
    "            unbatched_basenames = pd.Series(list(remaining_basenames_set))\n",
    "            \n",
    "            # Increment the batch counter\n",
    "            batch_number += 1\n",
    "\n",
    "    print(f\"Total batches checked: {batch_number}\")\n",
    "    print(f\"Total NEW batches created: {total_new_batches}\")\n",
    "    print(f\"Total TILE images processed: {total_tiles}\")\n",
    "    return batch_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transect batches\n",
    "collect_id = \"20240804_001_Iver3069_ABS2\"\n",
    "# collect_id = \"20240618_001_Iver3069_ABS2\"\n",
    "n_batches = export_batch_paths_tile_transect(collect_id = collect_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8106ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_transect_batch_image_labels(collect_id, batch = 0, copy=False):  # Change this to the desired batch number\n",
    "    # # Copy Batches\n",
    "    transect_update = f\"Z:\\\\__AdvancedTechnologyBackup\\\\04_ProjectData\\\\Innodata_2025\\\\Goby\\\\transects\\\\{collect_id}\"\n",
    "    path = transect_update + \"\\\\\" + f\"{collect_id}_batch_{batch:02d}\"\n",
    "    images, labels = Utils.read_list_txt(os.path.join(path, \"images.txt\")), Utils.read_list_txt(os.path.join(path, \"labels.txt\"))\n",
    "    img_folder, lbl_folder = os.path.join(path, \"images\"), os.path.join(path, \"labels\")\n",
    "    if copy:\n",
    "        Utils.copy_files_lst(images, img_folder)\n",
    "        Utils.copy_files_lst(labels, lbl_folder)\n",
    "    Utils.check_txt_file_vs_images(os.path.join(path, \"images.txt\"), img_folder)\n",
    "\n",
    "for b in [8]:\n",
    "    copy_transect_batch_image_labels(collect_id=\"20240618_001_Iver3069_ABS2\", batch = b, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6cff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Path Construction ---\n",
    "def get_im_lb_folders(batch, collect_id):\n",
    "    transect_update = f\"Z:\\\\__AdvancedTechnologyBackup\\\\04_ProjectData\\\\Innodata_2025\\\\Goby\\\\transects\\\\{collect_id}\"\n",
    "    batch_name = f\"{collect_id}_batch_{batch:02d}\"\n",
    "    path = os.path.join(transect_update, batch_name)\n",
    "    img_folder = os.path.join(path, \"images\")\n",
    "    lbl_folder = os.path.join(path, \"yolo_labels\")\n",
    "    return img_folder, lbl_folder\n",
    "\n",
    "\n",
    "# batches = [8]\n",
    "# collect_id = \"20240618_001_Iver3069_ABS2\"\n",
    "# for batch in batches:\n",
    "#     img_folder, lbl_folder = get_im_lb_folders(batch, collect_id)\n",
    "#     Utils.zip_folder(img_folder)\n",
    "#     Utils.zip_folder(lbl_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c81232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_path_0n = r\"..\\output\\validation\\detect\\test_sept_1fish\\test_run13_1n_curves.csv\"\n",
    "support_0n = df_abs2_meta_nf[(df_abs2_meta_nf.n_fish < 2)].shape[0]\n",
    "curve_path_2n = r\"..\\output\\validation\\detect\\test_sept_2-3fish\\test_run13_2-3n_curves.csv\"\n",
    "support_2n = df_abs2_meta_nf[(df_abs2_meta_nf.n_fish >= 2) & (df_abs2_meta_nf.n_fish <= 3)].shape[0]\n",
    "curve_path_4n = r\"..\\output\\validation\\detect\\test_sept_4fish+\\test_run13_4n+_curves.csv\"\n",
    "support_4n = df_abs2_meta_nf[(df_abs2_meta_nf.n_fish >= 4)].shape[0]\n",
    "curve_path_abs2 = r\"..\\output\\validation\\detect\\test_sept_abiss2\\test_run13_abiss2_curves.csv\"\n",
    "support_abs2 = df_abs2_meta_nf.shape[0]\n",
    "curve_path_abs1 = r\"..\\output\\validation\\detect\\test_sept_abiss1\\test_run13_abiss1_curves.csv\"\n",
    "support_abs1 = df_abs1_meta_nf.shape[0]\n",
    "df_0n, fmax_0n, cmax_0n, c_eq_0n, pr_eq_0n = Reports.get_metrics(curve_path_0n) \n",
    "df_2n, fmax_2n, cmax_2n, c_eq_2n, pr_eq_2n = Reports.get_metrics(curve_path_2n) \n",
    "df_4n, fmax_4n, cmax_4n, c_eq_4n, pr_eq_4n = Reports.get_metrics(curve_path_4n) \n",
    "dfabs2, fmaxabs2, cmaxabs2, c_eqabs2, pr_eqabs2 = Reports.get_metrics(curve_path_abs2) \n",
    "dfabs1, fmaxabs1, cmaxabs1, c_eqabs1, pr_eqabs1 = Reports.get_metrics(curve_path_abs1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_0n.precision, df_0n.recall, label=f\"ABISS2 only 1 fish, {support_0n}, {support_0n/support_abs2*100:0.1f}%\", color=\"purple\")\n",
    "plt.plot(df_2n.precision, df_2n.recall, label=f\"ABISS2 At 2-3 fish, {support_2n}, {support_2n/support_abs2*100:0.1f}%\", color=\"green\")\n",
    "plt.plot(df_4n.precision, df_4n.recall, label=f\"ABISS2 At least 4 fish, {support_4n}, {support_4n/support_abs2*100:0.1f}%\", color=\"orange\")\n",
    "plt.plot(dfabs1.precision, dfabs1.recall, label=f\"ABISS1 Test images, {support_abs1}\", color=\"red\")\n",
    "plt.xlabel('Recall') \n",
    "plt.ylabel('Precision') \n",
    "plt.title('Goby count bins Precision-Recall Curve')\n",
    "plt.legend() # 1461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8decc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dfabs2.precision, dfabs2.recall, label=f\"ABISS2 Test images, {support_abs2}\")\n",
    "plt.plot(dfabs1.precision, dfabs1.recall, label=f\"ABISS1 Test images, {support_abs1}\", color=\"red\")\n",
    "plt.xlabel('Recall') \n",
    "plt.ylabel('Precision') \n",
    "plt.title('ABISS1 vs ABISS2 Precision-Recall Curve')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f29f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = glob.glob(r\"Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\relabel\\2025_goby_relabel_initial_sample\\full\\Innodata Output\\Initial Re-Label Full\\json\\*.json\")\n",
    "image_lst = glob.glob(r\"Z:\\__AdvancedTechnologyBackup\\04_ProjectData\\Innodata_2025\\Goby\\relabel\\2025_goby_relabel_initial_sample\\full\\original\\images\\images\\*.png\")\n",
    "image_path = image_lst[2]\n",
    "json_path = json_files[2]\n",
    "Overlays.plot_coco_boxes(image_path, json_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yolov8v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
