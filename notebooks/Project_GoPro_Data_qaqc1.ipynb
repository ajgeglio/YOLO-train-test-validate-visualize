{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src import *\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gopro QAQC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Gopro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a dataframe of corresponding images and labels as they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the original images and labels\n",
    "def original_image_label_paths():\n",
    "    imgs_dan = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\Annotated_Images\\GoPro_FishSegmentation\\GoPro_FishSegmentation_FullSize\\Dan_Dataset\\images\\*.jpg\")\n",
    "    imgs_hard_substrat = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\Annotated_Images\\GoPro_FishSegmentation\\GoPro_FishSegmentation_FullSize\\Hard_Substrate\\images\\*.JPG\")\n",
    "    imgs_soft_substrat = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\Annotated_Images\\GoPro_FishSegmentation\\GoPro_FishSegmentation_FullSize\\Soft_Substrate\\images\\*.JPG\")\n",
    "    imgs_gopro = imgs_hard_substrat+imgs_soft_substrat + imgs_dan\n",
    "\n",
    "    pnglbls_hard_substrat = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\Annotated_Images\\GoPro_FishSegmentation\\GoPro_FishSegmentation_FullSize\\Hard_Substrate\\png_labels\\*.png\")\n",
    "    pngs_dan = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\Annotated_Images\\GoPro_FishSegmentation\\GoPro_FishSegmentation_FullSize\\Dan_Dataset\\png_labels\\*.png\")\n",
    "    pnglbls_soft_substrat = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\Annotated_Images\\GoPro_FishSegmentation\\GoPro_FishSegmentation_FullSize\\Soft_Substrate\\png_labels\\*.png\")\n",
    "    pnglbls = pnglbls_hard_substrat+pnglbls_soft_substrat + pngs_dan\n",
    "\n",
    "    yolo_dan = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\Annotated_Images\\GoPro_FishSegmentation\\GoPro_FishSegmentation_FullSize\\Dan_Dataset\\YOLO_labels\\*.txt\")\n",
    "    lbls_hard_substrat = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\Annotated_Images\\GoPro_FishSegmentation\\GoPro_FishSegmentation_FullSize\\Hard_Substrate\\Yolo_labels\\*.txt\")\n",
    "    lbls_soft_substrat = glob.glob(r\"Z:\\__Organized_Directories_InProgress\\Annotated_Images\\GoPro_FishSegmentation\\GoPro_FishSegmentation_FullSize\\Soft_Substrate\\Yolo_labels\\*.txt\")\n",
    "    lbls = lbls_hard_substrat+lbls_soft_substrat + yolo_dan\n",
    "\n",
    "    imgs_lbls_gopro = pd.DataFrame(np.c_[imgs_gopro, pnglbls, lbls], columns=[\"image_path\", \"png_label_path\", \"label_path\"]) #.sample(frac=1, random_state = 42)\n",
    "    # imgs_lbls_gopro[\"substrate\"] = imgs_lbls_gopro.image_path.str.extract(r'([A-Z][a-z]{3}_Substrate)')\n",
    "    imgs_lbls_gopro = imgs_lbls_gopro.reset_index(drop=True)\n",
    "    imgs_lbls_gopro['unique_filename'] = general.make_imgs_nms_unique(imgs_lbls_gopro.image_path)\n",
    "    imgs_lbls_gopro['image_id'] = imgs_lbls_gopro.unique_filename.apply(lambda x: x.split(\".\")[0])\n",
    "    assert imgs_lbls_gopro.shape == imgs_lbls_gopro.drop_duplicates(subset='image_id').shape\n",
    "    # imgs_lbls_gopro.to_csv(r'datasets\\GoPro_datasets\\GLSC_GoPro\\GoPro_img_lbl_pths_unique.csv')\n",
    "    # imgs_lbls_gopro = pd.read_csv(r'datasets\\GoPro_datasets\\GLSC_GoPro\\GoPro_img_lbl_pths_unique.csv', index_col=0)\n",
    "    imgs_lbls_gopro[\"image_id\"] = imgs_lbls_gopro.image_path.apply(lambda x: os.path.basename(x).split(\".\")[0])\n",
    "    print(imgs_lbls_gopro.shape)\n",
    "    return imgs_lbls_gopro\n",
    "imgs_lbls_gopro = original_image_label_paths()\n",
    "imgs_lbls_gopro[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dans_master_lbl_df():\n",
    "    dans = imgs_lbls_gopro[imgs_lbls_gopro.unique_filename.str.contains(\"Dan\")]\n",
    "    dans_master_gopro_yolo_labels = general.make_master_lbl_df_gopro(dans.label_path)\n",
    "    dans_master_gopro_yolo_labels = dans_master_gopro_yolo_labels.rename(columns={'cls': 'cls_l', \"x\":'x_l', \"y\":'y_l', \"w\":'w_l', \"h\":'h_l', 'fish_id': 'ground_truth_id'})\n",
    "    assert dans_master_gopro_yolo_labels.shape = dans_master_gopro_yolo_labels.drop_duplicates(subset=['x_l','y_l','w_l', 'h_l'])\n",
    "    return dans_master_gopro_yolo_labels\n",
    "dans_master_gopro_yolo_labels = dans_master_lbl_df()\n",
    "dans_master_gopro_yolo_labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous QAQC\n",
    "def glsc_infer_results_qaqc():\n",
    "    prev_qaqc_pths = glob.glob(r\"Z:\\Proj_Yolo\\GobyFinder_GoPro_Model_Results\\*_edit\\yolov8x_GoPro_*_scores_annot.xlsx\")\n",
    "    qaqc_dfs = [pd.read_excel(df, index_col=0) for df in prev_qaqc_pths]\n",
    "    qaqc_df = pd.concat(qaqc_dfs)\n",
    "    prev_scor_pths = glob.glob(r\"Z:\\Proj_Yolo\\GobyFinder_GoPro_Model_Results\\*_edit\\yolov8x_GoPro_*_scores.csv\")\n",
    "    score_dfs = [pd.read_csv(df, index_col=0) for df in prev_scor_pths]\n",
    "    score_df = pd.concat(score_dfs)\n",
    "    score_df = score_df.drop_duplicates(subset=['image_name','ground_truth_id', 'x_l', 'y_l', 'w_l', 'h_l'])\n",
    "    assert len(qaqc_df.detect_id.unique()) == len(qaqc_df)\n",
    "    assert len(score_df.detect_id.unique()) == len(score_df)\n",
    "    \n",
    "    qaqc_df = pd.merge(score_df[['image_name', 'detect_id', 'names_l', 'cls_l', 'x_l', 'y_l', 'w_l', 'h_l', 'im_h_l', 'im_w_l', 'ground_truth_id']], \n",
    "                        qaqc_df[[\"detect_id\", \"qaqc\"]], on = \"detect_id\")\n",
    "    assert qaqc_df.shape == qaqc_df.drop_duplicates(subset=['image_name', 'x_l', 'y_l', 'w_l', 'h_l']).shape\n",
    "    qaqc_df[\"image_id\"] = qaqc_df.image_name.apply(lambda x: x.split(\".\")[0])\n",
    "    qaqc_df = pd.merge(qaqc_df, dans_master_gopro_yolo_labels, on=[\"image_id\", \"ground_truth_id\", 'cls_l', 'x_l', 'y_l', 'w_l', 'h_l'], how = \"outer\")\n",
    "    qaqc_df = pd.merge(qaqc_df, imgs_lbls_gopro, on=\"image_id\")\n",
    "    \n",
    "    qaqc_df.qaqc = qaqc_df.qaqc.fillna(\"U\")\n",
    "    qaqc_df.qaqc = qaqc_df.qaqc.replace({1.0:\"Y\", 0.0:\"N\"})\n",
    "    qaqc_df.cls_l = qaqc_df.cls_l.astype(int)\n",
    "    return qaqc_df\n",
    "# use this dataset to create the qaqc dataset (dans not yet qaqc'd)\n",
    "# qaqc_df = glsc_infer_results_qaqc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the QAQC filter and moving to new filepath with unique filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gopro_qaqc_to_unique(qaqc_df):\n",
    "    for image_path in qaqc_df.image_path.unique():\n",
    "        df_sub = qaqc_df[qaqc_df.image_path == image_path]\n",
    "        df_sub = df_sub[(df_sub.qaqc==\"Y\") | (df_sub.qaqc==\"U\")]\n",
    "        if not df_sub.empty:\n",
    "            lbl = df_sub[[\"cls_l\", \"x_l\", \"y_l\", \"w_l\", \"h_l\"]]\n",
    "            id = df_sub.unique_filename.unique()[0].split(\".\")[0]\n",
    "            imdest = r\"datasets\\GoPro_datasets\\GLSC_unique_qaqc\\images\"\n",
    "            lbdest = r\"datasets\\GoPro_datasets\\GLSC_unique_qaqc\\labels\"\n",
    "            lbl.to_csv(os.path.join(lbdest,id+\".txt\"), index=None, sep=\" \", header=None)\n",
    "            shutil.copy2(image_path, os.path.join(imdest, id+\".jpg\"))\n",
    "# gopro_qaqc_to_unique(qaqc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMBS Gopro qaqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hillary Inference\n",
    "## make dataframe of original image paths and unique image names\n",
    "def lmbs_infer_results_qaqc():\n",
    "    LMBS_Goby_img_pths = general.list_files(r\"datasets\\GoPro_datasets\\LMBS_original\", \".jpg\")\n",
    "    unique_names = general.make_imgs_nms_unique(LMBS_Goby_img_pths)\n",
    "    LMBS_Goby_Photos_df = pd.DataFrame(np.c_[LMBS_Goby_img_pths, unique_names], columns=[\"image_path\", \"filename\"])\n",
    "    # combine inference results with qaqc checks and image paths\n",
    "    infer_results = pd.read_csv(r\"datasets\\GoPro_datasets\\LMBS_original\\LMBS_conf0.05_QAQC\\LMBS_Goby_Photos_conf0.05_Yolo_predictions.csv\", index_col=0)\n",
    "    infer_results['orig_filename'] = infer_results.filename.apply(lambda x: x.split(\"_\")[-1])\n",
    "    assert infer_results.shape == infer_results.drop_duplicates(subset=['filename', 'x', 'y', 'w', 'h']).shape\n",
    "    qaqc_results = pd.read_excel(r\"datasets\\GoPro_datasets\\LMBS_original\\LMBS_conf0.05_QAQC\\LMBS_Goby_Photos_conf0.05_Yolo_predictions_QAQC_Nov2024_TO_USGS.xlsx\", index_col=0)\n",
    "    qaqc_results = qaqc_results.rename(columns={\"filename\":\"orig_filename\", \"detect_id\":\"plot_id\", \"CHECK\":\"qaqc\"})\n",
    "    qaqc_results['image_id'] = qaqc_results.orig_filename.apply(lambda x: x.split(\".\")[0])\n",
    "    qaqc_results['path_id'] = qaqc_results.path.apply(lambda x: x.replace(\"/\",\"_\"))\n",
    "    qaqc_results['plot_id'] = qaqc_results.plot_id.apply(lambda x: x.replace(\" \",\"_\"))\n",
    "    qaqc_results['detect_id'] = qaqc_results.path_id + \"_\" + qaqc_results.image_id + \"_\" + qaqc_results.plot_id\n",
    "    assert qaqc_results.shape == qaqc_results.drop_duplicates(subset=\"detect_id\").shape\n",
    "    infer_results = pd.merge(infer_results, qaqc_results[[\"detect_id\", \"qaqc\"]], on = \"detect_id\")\n",
    "    infer_results = pd.merge(infer_results, LMBS_Goby_Photos_df, on=\"filename\")\n",
    "    assert infer_results.shape == infer_results.drop_duplicates(subset=['filename', 'x', 'y', 'w', 'h']).shape\n",
    "    return infer_results\n",
    "#use this dataframe to create new dataset\n",
    "# lmbs_infer_results_qaqc = lmbs_infer_results_qaqc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the QAQC filter and moving to new filepath with unique filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lmbs_gopro_qaqc_to_unique(lmbs_infer_results_qaqc):\n",
    "    for image_path in lmbs_infer_results_qaqc.image_path.unique():\n",
    "        df_sub = lmbs_infer_results_qaqc[lmbs_infer_results_qaqc.image_path == image_path]\n",
    "        df_sub = df_sub[df_sub.qaqc==\"Y\"]\n",
    "        if not df_sub.empty:\n",
    "            lbl = df_sub[[\"cls\", \"x\", \"y\", \"w\", \"h\"]]\n",
    "            id = df_sub.filename.unique()[0].split(\".\")[0]\n",
    "            imdest = r\"datasets\\GoPro_datasets\\LBMS_unique_qaqc\\images\"\n",
    "            lbdest = r\"datasets\\GoPro_datasets\\LBMS_unique_qaqc\\labels\"\n",
    "            lbl.to_csv(os.path.join(lbdest,id+\".txt\"), index=None, sep=\" \", header=None)\n",
    "            shutil.copy2(image_path, os.path.join(imdest, id+\".jpg\"))\n",
    "lmbs_gopro_qaqc_to_unique(lmbs_infer_results_qaqc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def get_im_w(image_path):\n",
    "    im = Image.open(image_path)\n",
    "    w, h = im.size\n",
    "    return w\n",
    "def get_im_h(image_path):\n",
    "    im = Image.open(image_path)\n",
    "    w, h = im.size\n",
    "    return h\n",
    "lim_w = lambda f: get_im_w(f)\n",
    "lim_h = lambda f: get_im_h(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_all = glob.glob(r\"datasets\\GoPro_datasets\\GLSC_unique_qaqc\\images\\*.jpg\") + glob.glob(r\"datasets\\GoPro_datasets\\LBMS_unique_qaqc\\images\\*.jpg\")\n",
    "lbls_all = glob.glob(r\"datasets\\GoPro_datasets\\GLSC_unique_qaqc\\labels\\*.txt\") + glob.glob(r\"datasets\\GoPro_datasets\\LBMS_unique_qaqc\\labels\\*.txt\")\n",
    "gopro_all = generate_splits(img_pth_lst = imgs_all, bbox_pths=lbls_all, mer_pths=None).return_merged()\n",
    "gopro_all[\"imh\"], gopro_all[\"imw\"] = gopro_all.image_path.apply(lim_h), gopro_all.image_path.apply(lim_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gopro_all.groupby(by=[\"imh\",\"imw\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train_test_valid_split(df, train_split=0.6, valid_split=0.2):\n",
    "    l = len(df)\n",
    "    print(\"n samples:\", l)\n",
    "    train_df = df.sample(int(train_split*l), random_state=42)\n",
    "    df = df.drop(train_df.index)\n",
    "    valid_df = df.sample(int(valid_split*l), random_state=42)\n",
    "    df = df.drop(valid_df.index)\n",
    "    test_df = df\n",
    "    X_train, y_train = train_df.image_path.values, train_df.bbox_path.values\n",
    "    X_valid, y_valid = valid_df.image_path.values, valid_df.bbox_path.values\n",
    "    X_test, y_test = test_df.image_path.values, test_df.bbox_path.values\n",
    "    print(f\"training, testing, validation, {X_train.shape[0]}, {X_test.shape[0]},{X_valid.shape[0]}\")\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test, train_df, valid_df, test_df\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test, train_df, valid_df, test_df = do_train_test_valid_split(gopro_all, train_split=0.77, valid_split=0.115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy images and labels\n",
    "import shutil\n",
    "def cpy_lbls(set, dst):\n",
    "    if not os.path.exists(dst): os.makedirs(dst)\n",
    "    for item in set:\n",
    "        shutil.copy2(item, dst)\n",
    "root =  r\"datasets\\GoPro_datasets\\GLSC_LMBS_dataset\"\n",
    "# cpy_lbls(y_train, os.path.join(root, \"train\\\\labels\"))\n",
    "# cpy_lbls(y_valid, os.path.join(root, \"validation\\\\labels\"))\n",
    "# cpy_lbls(y_test, os.path.join(root, \"test\\\\labels\"))\n",
    "# cpy_lbls(X_train, os.path.join(root, \"train\\\\images\"))\n",
    "# cpy_lbls(X_valid, os.path.join(root, \"validation\\\\images\"))\n",
    "# cpy_lbls(X_test, os.path.join(root, \"test\\\\images\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches for MakeSense.ai QAQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r\"datasets\\GoPro_datasets\\GLSC_unique_qaqc\"\n",
    "def create_batch_gopro_qaqc(root):\n",
    "    batch_folder = \"QAQC_batches\"\n",
    "    images = sorted(glob.glob(os.path.join(root, \"images\", \"*.jpg\")))\n",
    "    labels = sorted(glob.glob(os.path.join(root, \"labels\",\"*.txt\")))\n",
    "    assert len(images) == len(labels), \"images labels do not match\"\n",
    "\n",
    "    def chunk_list(lst, chunk_size=100):\n",
    "        # Using list comprehension to break the list into chunks\n",
    "        return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
    "    \n",
    "    chunks_im = chunk_list(images)\n",
    "    chunks_lb = chunk_list(labels)\n",
    "    for idx, im_lst, lb_lst in zip(range(len(chunks_im)), chunks_im, chunks_lb):\n",
    "        dirname = os.path.join(root, batch_folder, f\"batch_{idx}\")\n",
    "        for imsrc, lbsrc in zip(im_lst, lb_lst):\n",
    "            imdst = os.path.join(dirname, \"images\")\n",
    "            lbdst = os.path.join(dirname, \"labels\")\n",
    "            if not os.path.exists(imdst): os.makedirs(imdst)\n",
    "            if not os.path.exists(lbdst): os.makedirs(lbdst)\n",
    "            shutil.copy2(imsrc, imdst)\n",
    "            shutil.copy2(lbsrc, lbdst)\n",
    "        # after copies, make labels.txt files\n",
    "        definition_lst = os.path.join(dirname, \"labels.txt\")\n",
    "        lst = os.listdir(lbdst)\n",
    "        general.write_list_txt(definition_lst, lst)\n",
    "        shutil.copy(definition_lst, lbdst)\n",
    "# create_batch_gopro_qaqc(root)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yolov8v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
